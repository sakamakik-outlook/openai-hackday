{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install requests # To get error text from http server\n",
    "import openai\n",
    "import requests\n",
    "openai.api_key=\"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\"  # Replace this with your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the function to get MF source code\n",
    "def get_source_code(fine_name=\"program.txt\"):\n",
    "\n",
    "    url = \"https://raw.githubusercontent.com/SoftwareAG/adabas-natural-code-samples/main/Last%20Day%20of%20a%20Month/program.txt\"\n",
    "\n",
    "    return requests.get(url).text\n",
    "\n",
    "\n",
    "# Function to be passed to OpenAI API\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_source_code\",\n",
    "        \"description\": \"get an adabas nantural source code\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"filename\": {\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard GPT model cannot answer a question about a specific function.\n",
    "#### GPT: \"Without the actual content of the source code in program.txt, it is not possible to determine what it does. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without the actual content of the source code in program.txt, it is not possible to determine what it does. The description of the functionality or purpose of the source code is required to provide an answer.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"\"\"\n",
    "        What does this source code do - program.txt?\n",
    "    \"\"\"}]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages\n",
    "    )\n",
    "\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we add a source code with the question, GPT is able to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The source code is a program that takes in a source date (either in alpha or date format) and calculates the last day of the month that precedes the source date. \n",
      "\n",
      "The program first handles the date format source by deriving the first day of the month for the source date. It then subtracts one from the \"intermediate\" date to produce the last day of the preceding month. \n",
      "\n",
      "Next, the program handles the alpha source by creating the first day of the month in alpha format. It then converts it to date format and subtracts one to produce the desired last day of the previous month.\n",
      "\n",
      "The output of the program includes the source date and the calculated last day of the preceding month for both the date format and alpha format sources.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"\"\"\n",
    "         What does this source code do - program.txt?\n",
    "    \"\"\"}]\n",
    "\n",
    "# Step 1: call the API\n",
    "response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages, \n",
    "        functions=functions,   # <---- this is the new part. Pass the functions to the API.\n",
    "        function_call=\"auto\",\n",
    "        )\n",
    "\n",
    "response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "# Step 2: check if GPT wanted to call a function\n",
    "if response_message.get(\"function_call\"):\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "                \"get_source_code\": get_source_code,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        fuction_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        function_response = fuction_to_call(\n",
    "                fine_name=function_args.get(\"filename\")\n",
    "        )\n",
    "\n",
    "        # Step 4: send the info on the function call and function response to GPT\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        messages.append(\n",
    "                {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "                }\n",
    "        )  # extend conversation with function response\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-0613\",\n",
    "                messages=messages,\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "        print(second_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
