{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install requests # To get error text from http server\n",
    "import openai\n",
    "import requests\n",
    "openai.api_key=\"sk-***\"  # Replace this with your API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an API to retrieve log details from external site. \n",
    "### Using a static file stored in git in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the function to get an error text\n",
    "def get_error_message(msg_id=\"123456\"):\n",
    "\n",
    "    # This is a sample error message static text. This needs to be replaced by a db call or log file read\n",
    "    url = \"https://raw.githubusercontent.com/sakamakik-outlook/openai-hackday/main/data/errorlog.txt\"\n",
    "\n",
    "    return requests.get(url).text\n",
    "\n",
    "\n",
    "# Function to be passed to OpenAI API\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_error_message\",\n",
    "        \"description\": \"Get the error message for a given message id\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"msg_id\": {\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard OpenAI API call without any log info. \n",
    "### GPT cannot answer the question, saying \"I don't have access to personal information or specific messages.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, as an AI language model, I don't have access to personal information or specific messages. Therefore, I cannot tell you what happened to a specific message like 123456.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"\"\"\n",
    "        What happened to my message 123456?\n",
    "    \"\"\"}]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages\n",
    "    )\n",
    "\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a function to the parameters. \n",
    "### 1. GPT will check if the function call is required. If yes, it returns \"function_call\" in the response\n",
    "### 2. If \"function_call\" is returned, we execute the function and get the result\n",
    "### 3. Run a new API call with the queston + result of function call (Error log in this case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7dtjoYElkzLJkj07iPiRmgR9mtUSG\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1689743404,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Based on the error message, it appears that there was a connection failure while processing your message with ID 123456. The error indicates that there was a problem with the database connection, specifically with the host name or IP address \\\"10.1.1.1\\\" and the service name or port number 446. The error code is -4498 and the SQL state is 08506. \\n\\nIt seems that the connection was re-established, but there may have been some impact on the processing of your message. You may need to review the logs or contact the relevant support team to investigate further and determine the status of your message.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 1509,\n",
      "    \"completion_tokens\": 128,\n",
      "    \"total_tokens\": 1637\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"\"\"\n",
    "        What happened to my message 123456?\n",
    "    \"\"\"}]\n",
    "\n",
    "# Step 1: call the API\n",
    "response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages, \n",
    "        functions=functions,   # <---- this is the new part. Pass the functions to the API.\n",
    "        function_call=\"auto\",\n",
    "        )\n",
    "\n",
    "response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "# Step 2: check if GPT wanted to call a function\n",
    "if response_message.get(\"function_call\"):\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "                \"get_error_message\": get_error_message,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        fuction_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        function_response = fuction_to_call(\n",
    "                msg_id=function_args.get(\"msg_id\")\n",
    "        )\n",
    "\n",
    "        # Step 4: send the info on the function call and function response to GPT\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        messages.append(\n",
    "                {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "                }\n",
    "        )  # extend conversation with function response\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-0613\",\n",
    "                messages=messages,\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "        print(second_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
